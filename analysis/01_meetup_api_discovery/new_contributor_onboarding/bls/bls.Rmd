---
title: "Bureau of Labor Statistics"
author: "Augustina Ragwitz"
date: "July 28, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(geosphere)
library(ggmap)
library(purrr)
library(stringr)
library(tabulizer)
library(tidyr)
```


# Quarterly Census of Employment and Wages

## Region codes
```{r qcew_region_codes, echo=FALSE, eval=FALSE}
download.file("https://data.bls.gov/cew/doc/titles/area/area_titles.csv",
              "downloads/bls_qcew_area_titles.csv")
```

## Longitude and Latitude Lookup

This will allow us to cross-reference with Meetup

First strategy is to do lookups by county specific to states and compute their distance to the city of interest. This will not cover entire metro areas so it could be misleading.

Another method further down simply looks for cities of interest in the "metro statistics" area and makes a manual selection.

```{r meetup_geo_states, echo=FALSE, eval=FALSE}

meetup_geo <- read.csv("../tech_meetups/meetup_geo.csv")

# set state abbreviations
data(state)

meetup_geo_states <- merge(
  meetup_geo,
  data_frame(state_abb=state.abb, state_name=state.name),
  by.x="state",
  by.y="state_abb"
)

write.csv(meetup_geo_states, "qcew/meetup_geo_states.csv", row.names = FALSE)
```


```{r qcew_region_cxref, echo=FALSE}
# to filter qcew areas
meetup_geo_states <- read.csv("qcew/meetup_geo_states.csv")

# list of areas the qcew is divided into
qcew_areas <- read.csv("downloads/bls_qcew_area_titles.csv")
qcew_areas <- qcew_areas %>% mutate(area_title=as.character(area_title))

```


```{r}
# find metro areas
qcew_areas_msa <- qcew_areas %>% 
  separate(area_title, c("area_descr", "area_state"), ", ", 
           remove=FALSE, extra="merge", fill="right") %>%
  filter(! is.na(str_match(area_state, "MSA"))) %>%
  separate(area_state, c("msa_state", "msa"), " ") %>%
  mutate(msa_states = strsplit(msa_state, "-")) %>% 
  unnest(msa_states) %>%
  mutate(msa_cities = strsplit(area_descr, "-")) %>%
  unnest(msa_cities)

qcew_msa_lookup <- merge(
  meetup_geo_states %>% select(state_name, state, city, city_state),
  qcew_areas_msa %>% select(msa_states, msa_cities, area_fips),
  by.x=c("state", "city"),
  by.y=c("msa_states", "msa_cities"))

qcew_msa_lookup <- merge(
  qcew_msa_lookup,
  qcew_areas_msa %>% select(area_fips, msa_states, msa_cities, area_title),
  by="area_fips"
)

write.csv(qcew_msa_lookup, "qcew/qcew_msa.csv", row.names = FALSE)
```


```{r}
# build url for source data
qcew_area_msa_fips <- qcew_msa_lookup %>% group_by(area_fips) %>% summarise()
qcew_url <- "http://www.bls.gov/cew/data/api/$Y/$Q/area/$FIP.csv"

qcew_url_y <- map_df(2012:2016, ~ data_frame(link_y=str_replace(
                                         qcew_url, "\\$Y", as.character(.x))))

qcew_url_q <- map_df(1:4, ~ data_frame(link_q=str_replace(
                                         qcew_url_y$link_y, "\\$Q", as.character(.x))))

qcew_area_msa_links <- map_df(qcew_area_msa_fips$area_fips, 
                       ~ data_frame(fip=.x,
                                    link_fip=str_replace(qcew_url_q$link_q, "\\$FIP", as.character(.x))))

qcew_area_msa_links <- qcew_area_msa_links %>% 
  group_by(fip) %>% mutate(file=paste("downloads/", fip, row_number(), ".csv", sep="_"))

write.csv(qcew_area_msa_links, "qcew/qcew_area_msa_links.csv", row.names = FALSE)
```

Download CSV files from BLS
```{r}

# this seems to be broken but the files looks ok

qcew_area_msa_links %>% do(tryCatch(download.file(.$link_fip, .$file),
                                    error=function (e) {
                                      print(paste("Error downloading", .$link_fip, "to", .$file))
                                    },
                                    finally=print(paste("Saving", .$link_fip, "to", .$file))))

```

Make a big dataframe
```{r}
qcew_area_msa_files <- bind_rows(map_df(qcew_area_msa_links$file, function(x){read.csv(file=x,header=T)}))
write.csv(qcew_area_msa_files, "qcew/qcew_area_msa.csv", row.names=FALSE)
```

### County Geolocation

Could be useful later depending on what data are available from QCEW. Cross-ref with Metro areas above.

This takes forever, you really don't want to run this unless you have to. This is a filtered list based on states of interest.

```{r qcew_geocode, eval=FALSE}
qcew_geo <- geocode(qcew_areas_join$area_title)
write.csv(qcew_geo, "qcew/qcew_geo.csv")
```

```{r, echo=FALSE}
qcew_areas_split <- qcew_areas %>% 
  separate(area_title, c("area_descr", "area_state"), ", ", 
           remove=FALSE, extra="merge", fill="right")

qcew_areas_join <- merge(meetup_geo_states %>% select(state_name, state, city, city_state), 
                         qcew_areas_split, by.x="state_name", by.y="area_state")
```

```{r clean_qcew_geocode}
qcew_geo <- read.csv("qcew/qcew_geo.csv")
# link up names and geos
qcew_area_lookup <- bind_cols(qcew_areas_join, qcew_geo)
qcew_area_lookup <- qcew_area_lookup %>% 
  mutate(lon_county=lon, lat_county=lat) %>%
  filter(!is.na(lon) & !is.na((lat))) %>%
  filter(area_descr=="Out-of-State") %>%
  select(city, city_state, state, state_name, area_fips, area_title, area_descr, lon_county, lat_county )
```

```{r build_qcew_city_geo}

# get city lon/lat from meetup data
qcew_city_geo <- merge(qcew_area_lookup, 
                       meetup_geo_states %>% select(city_state, lon, lat), 
                       by="city_state")
```



Function to compute distance between lon/lat if needed
```{r distance_miles}
# x is a lon/lat pair c(lon, lat)
distance_miles <- function (x=c(lon, lat)) {
  distm(x, c(lon_county, lat_county), fun = distHaversine)*0.000621371}
```


## NAICS Industry Codes

What industry codes should be included in "Tech Industry"?

Paytas, Jerry, and Dan Berglund. "Technology industries and occupations for NAICS industry data." Pittsburgh: Carnegie Mellon Center for Economic Development and State Science and Technology Institute (2004). http://ssti.org/report-archive/NAICS_Tech1.pdf

Markusen, Ann, et al. "Gauging Metropolitan “High-Tech” and “I-Tech” Activity." Minneapolis, MN (2001). https://s3.amazonaws.com/academia.edu.documents/34059711/hightech.pdf

```{r naics_tech_codes_download, echo=FALSE}
download.file("http://ssti.org/report-archive/NAICS_Tech1.pdf", "downloads/ssti_naics_tech_codes.pdf")
```

```{r naics_tech_codes}
naics_extracts <- extract_tables("downloads/ssti_naics_tech_codes.pdf",
                                  pages=c(4:7), method="data.frame") %>%
  reduce(bind_rows)

# combine Industry for wrapped lines
naics_extracts_fix_rows <- naics_extracts %>% 
  filter(is.na(NAICS.6.NAICS.Industry)) %>%
  mutate(NAICS4_na = is.na(NAICS.4),
    NAICS.4=ifelse(NAICS4_na, lead(NAICS.4), NAICS.4),
    NAICS.6=as.character(ifelse(NAICS4_na, lead(NAICS.6), NAICS.6)),
    NAICS.Industry=ifelse(NAICS4_na, paste(NAICS.Industry, lead(NAICS.Industry)), NAICS.Industry),
    NAICS4_na_prev=lag(NAICS4_na) & row_number() > 1
    ) %>%
  filter(!NAICS4_na_prev) %>% # remove rows for wrapped lines
  select(NAICS.4, NAICS.6, NAICS.Industry)

# some pages had the columns munged
naics_extracts_fix_cols <- naics_extracts %>% 
  filter(! is.na(NAICS.6.NAICS.Industry)) %>% 
  select(NAICS.4, NAICS.6.NAICS.Industry) %>%
  mutate(NAICS4_na = is.na(NAICS.4), # prepend space to extra row so seperate doesn't munge it
         NAICS.6.NAICS.Industry= ifelse(NAICS4_na, 
                                        paste(" ", NAICS.6.NAICS.Industry), 
                                        NAICS.6.NAICS.Industry),
         NAICS4_na_prev=lag(NAICS4_na) & row_number() > 1) %>%
  separate(NAICS.6.NAICS.Industry, c("NAICS.6", "NAICS.Industry"), 
           sep=" ", extra="merge", convert=FALSE) %>%
  mutate(NAICS.Industry=ifelse(NAICS4_na_prev, # combine Industry for wrapped lines
                                       paste(NAICS.Industry, lag(NAICS.Industry)),
                                       NAICS.Industry)) %>%
  filter(!NAICS4_na) %>% # remove rows for wrapped lines
  select(NAICS.4, NAICS.6, NAICS.Industry)

naics_tech <- merge(naics_extracts_fix_cols, naics_extracts_fix_rows, 
                    by=c("NAICS.4", "NAICS.6", "NAICS.Industry"), all=TRUE) 

# save extracted naic codes
write.csv(naics_tech, "qcew/naics_tech.csv", row.names = FALSE)

```

Some industry codes changed since 2012, so we need to create a lookup table to make sure they are correctly consolidated.

```{r naics_changes}

download.file("https://www.bls.gov/cew/bls_naics/2017_changes.csv", "downloads/naics_changes_2017.csv")

# TODO

```


## QCEW Tech

Extract rows from the QCEW report for Tech Industry NAIC codes

```{r qcew_area_msa_tech}

qcew_area_msa <- read.csv("qcew/qcew_area_msa.csv")

naics_tech <- read.csv("qcew/naics_tech.csv")

qcew_area_msa_tech_join <- merge(qcew_area_msa, naics_tech, by.x="industry_code", by.y="NAICS.6")

qcew_msa_lookup <- read.csv("qcew/qcew_msa.csv")
qcew_msa_meetup <- qcew_msa_lookup %>% 
  select(area_fips, area_title, state, city, state_name, city_state)

# add city info from Meetup
qcew_area_msa_tech <- merge(qcew_area_msa_tech_join, qcew_msa_meetup, by="area_fips")
qcew_area_msa_tech <- unique(qcew_area_msa_tech)

write.csv(qcew_area_msa_tech, "qcew/qcew_area_msa_tech.csv", row.names = FALSE)
```

